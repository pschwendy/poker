{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Notebook for Kaggle runs (with 30hr of free GPU) #\n",
    "####################################################\n",
    "\n",
    "# All important files of the repository jammed into one big file\n",
    "\n",
    "\n",
    "# EVALUATION FILES FIRST\n",
    "\n",
    "# evaluation/eval_card.py\n",
    "\n",
    "# From https://github.com/keithlee96/pluribus-poker-AI/blob/develop/poker_ai/poker/evaluation/eval_card.py\n",
    "# Binary Representation of Cards\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "class EvaluationCard:\n",
    "    \"\"\"\n",
    "    Static class that handles cards. We represent cards as 32-bit integers, so\n",
    "    there is no object instantiation - they are just ints. Most of the bits are\n",
    "    used, and have a specific meaning. See below:\n",
    "\n",
    "                                    EvaluationCard:\n",
    "\n",
    "                          bitrank     suit rank   prime\n",
    "                    +--------+--------+--------+--------+\n",
    "                    |xxxbbbbb|bbbbbbbb|cdhsrrrr|xxpppppp|\n",
    "                    +--------+--------+--------+--------+\n",
    "\n",
    "        1) p = prime number of rank (deuce=2,trey=3,four=5,...,ace=41)\n",
    "        2) r = rank of card (deuce=0,trey=1,four=2,five=3,...,ace=12)\n",
    "        3) cdhs = suit of card (bit turned on based on suit of card)\n",
    "        4) b = bit turned on depending on rank of card\n",
    "        5) x = unused\n",
    "\n",
    "    This representation will allow us to do very important things like:\n",
    "    - Make a unique prime prodcut for each hand\n",
    "    - Detect flushes\n",
    "    - Detect straights\n",
    "\n",
    "    and is also quite performant.\n",
    "    \"\"\"\n",
    "\n",
    "    # the basics\n",
    "    STR_RANKS = \"23456789TJQKA\"\n",
    "    INT_RANKS = range(13)\n",
    "    PRIMES = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41]\n",
    "\n",
    "    # conversion from string => int\n",
    "    CHAR_RANK_TO_INT_RANK = dict(zip(list(STR_RANKS), INT_RANKS))\n",
    "    INT_SUIT_TO_BINARY_SUIT = {\n",
    "        1: 1,  # spades\n",
    "        2: 2,  # hearts\n",
    "        3: 4,  # diamonds\n",
    "        4: 8,  # clubs\n",
    "    }\n",
    "    INT_SUIT_TO_CHAR_SUIT = \"xshxdxxxc\"\n",
    "\n",
    "    # for pretty printing\n",
    "    PRETTY_SUITS = {\n",
    "        1: chr(9824),  # spades\n",
    "        2: chr(9829),  # hearts\n",
    "        4: chr(9830),  # diamonds\n",
    "        8: chr(9827),  # clubs\n",
    "    }\n",
    "\n",
    "    # hearts and diamonds\n",
    "    PRETTY_REDS = [2, 4]\n",
    "\n",
    "    @staticmethod\n",
    "    def new(card: np.array):\n",
    "        \"\"\"\n",
    "        Converts EvaluationCard np.array to binary integer representation of card, inspired by:\n",
    "\n",
    "        http://www.suffecool.net/poker/evaluator.html\n",
    "        \"\"\"\n",
    "\n",
    "        rank_int = card[0]\n",
    "        suit_int = card[1]\n",
    "        # rank_int = EvaluationCard.INT_SUIT_TO_BINARY_SUIT[rank_int]\n",
    "        suit_int = EvaluationCard.INT_SUIT_TO_BINARY_SUIT[suit_int]\n",
    "        rank_prime = EvaluationCard.PRIMES[rank_int]\n",
    "\n",
    "        bitrank = 1 << rank_int << 16\n",
    "        suit = suit_int << 12\n",
    "        rank = rank_int << 8\n",
    "\n",
    "        return bitrank | suit | rank | rank_prime\n",
    "\n",
    "    @staticmethod\n",
    "    def int_to_str(card_int):\n",
    "        rank_int = EvaluationCard.get_rank_int(card_int)\n",
    "        suit_int = EvaluationCard.get_suit_int(card_int)\n",
    "        return EvaluationCard.STR_RANKS[rank_int] + EvaluationCard.INT_SUIT_TO_CHAR_SUIT[suit_int]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_rank_int(card_int):\n",
    "        return (card_int >> 8) & 0xF\n",
    "\n",
    "    @staticmethod\n",
    "    def get_suit_int(card_int):\n",
    "        return (card_int >> 12) & 0xF\n",
    "\n",
    "    @staticmethod\n",
    "    def get_bitrank_int(card_int):\n",
    "        return (card_int >> 16) & 0x1FFF\n",
    "\n",
    "    @staticmethod\n",
    "    def get_prime(card_int):\n",
    "        return card_int & 0x3F\n",
    "\n",
    "    @staticmethod\n",
    "    def hand_to_binary(card_strs):\n",
    "        \"\"\"\n",
    "        Expects a list of cards as strings and returns a list\n",
    "        of integers of same length corresponding to those strings.\n",
    "        \"\"\"\n",
    "        bhand = []\n",
    "        for c in card_strs:\n",
    "            bhand.append(EvaluationCard.new(c))\n",
    "        return bhand\n",
    "\n",
    "    @staticmethod\n",
    "    def prime_product_from_hand(card_ints):\n",
    "        \"\"\"\n",
    "        Expects a list of cards in integer form.\n",
    "        \"\"\"\n",
    "        product = 1\n",
    "        for c in card_ints:\n",
    "            product *= c & 0xFF\n",
    "        return product\n",
    "\n",
    "    @staticmethod\n",
    "    def prime_product_from_rankbits(rankbits):\n",
    "        \"\"\"\n",
    "        Returns the prime product using the bitrank (b)\n",
    "        bits of the hand. Each 1 in the sequence is converted\n",
    "        to the correct prime and multiplied in.\n",
    "\n",
    "        Params:\n",
    "            rankbits = a single 32-bit (only 13-bits set) integer representing\n",
    "                    the ranks of 5 _different_ ranked cards\n",
    "                    (5 of 13 bits are set)\n",
    "\n",
    "        Primarily used for evaulating flushes and straights,\n",
    "        two occasions where we know the ranks are *ALL* different.\n",
    "\n",
    "        Assumes that the input is in form (set bits):\n",
    "\n",
    "                              rankbits\n",
    "                        +--------+--------+\n",
    "                        |xxxbbbbb|bbbbbbbb|\n",
    "                        +--------+--------+\n",
    "\n",
    "        \"\"\"\n",
    "        product = 1\n",
    "        for i in EvaluationCard.INT_RANKS:\n",
    "            # if the ith bit is set\n",
    "            if rankbits & (1 << i):\n",
    "                product *= EvaluationCard.PRIMES[i]\n",
    "        return product\n",
    "\n",
    "    @staticmethod\n",
    "    def int_to_binary(card_int):\n",
    "        \"\"\"\n",
    "        For debugging purposes. Displays the binary number as a\n",
    "        human readable string in groups of four digits.\n",
    "        \"\"\"\n",
    "        bstr = bin(card_int)[2:][::-1]  # chop off the 0b and THEN reverse string\n",
    "        output = list(\"\".join([\"0000\" + \"\\t\"] * 7) + \"0000\")\n",
    "\n",
    "        for i in range(len(bstr)):\n",
    "            output[i + int(i / 4)] = bstr[i]\n",
    "\n",
    "        # output the string to console\n",
    "        output.reverse()\n",
    "        return \"\".join(output)\n",
    "\n",
    "    @staticmethod\n",
    "    def int_to_pretty_str(card_int):\n",
    "        \"\"\"\n",
    "        Prints a single card\n",
    "        \"\"\"\n",
    "\n",
    "        color = False\n",
    "        try:\n",
    "            from termcolor import colored\n",
    "            # for mac, linux: http://pypi.python.org/pypi/termcolor\n",
    "            # can use for windows: http://pypi.python.org/pypi/colorama\n",
    "            color = True\n",
    "        except ImportError:\n",
    "            pass\n",
    "\n",
    "        # suit and rank\n",
    "        suit_int = EvaluationCard.get_suit_int(card_int)\n",
    "        rank_int = EvaluationCard.get_rank_int(card_int)\n",
    "\n",
    "        # if we need to color red\n",
    "        s = EvaluationCard.PRETTY_SUITS[suit_int]\n",
    "        if color and suit_int in EvaluationCard.PRETTY_REDS:\n",
    "            s = colored(s, \"red\")\n",
    "\n",
    "        r = EvaluationCard.STR_RANKS[rank_int]\n",
    "\n",
    "        return f\"[{r}{s}]\"\n",
    "\n",
    "    @staticmethod\n",
    "    def print_pretty_card(card_int):\n",
    "        \"\"\"\n",
    "        Expects a single integer as input\n",
    "        \"\"\"\n",
    "        print(EvaluationCard.int_to_pretty_str(card_int))\n",
    "\n",
    "    @staticmethod\n",
    "    def print_pretty_cards(card_ints):\n",
    "        \"\"\"\n",
    "        Expects a list of cards in integer form.\n",
    "        \"\"\"\n",
    "        output = \" \"\n",
    "        for i in range(len(card_ints)):\n",
    "            c = card_ints[i]\n",
    "            if i != len(card_ints) - 1:\n",
    "                output += str(EvaluationCard.int_to_pretty_str(c)) + \",\"\n",
    "            else:\n",
    "                output += str(EvaluationCard.int_to_pretty_str(c)) + \" \"\n",
    "\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# deck.py\n",
    "class Deck:\n",
    "    _ranks = range(13)\n",
    "    _suits = [1, 2, 3, 4]\n",
    "\n",
    "    def __init__(self):\n",
    "        self._deck = self._create_deck()\n",
    "        self.pos = 0\n",
    "\n",
    "    def _create_deck(self):\n",
    "        ranks = np.tile(self._ranks, len(self._suits))\n",
    "        suits = np.repeat(self._suits, len(self._ranks))\n",
    "\n",
    "        return np.array([ranks, suits]).T\n",
    "\n",
    "    def _shuffle(self):\n",
    "        np.random.shuffle(self._deck)\n",
    "\n",
    "    def deal(self, n=1):\n",
    "        cards = self._deck[self.pos: self.pos + n].tolist()\n",
    "        self.pos += n\n",
    "        return cards\n",
    "\n",
    "    def simulate_deal(self, n=3):\n",
    "        cards = self._deck[self.pos: self.pos + n].tolist()\n",
    "        return cards\n",
    "    \n",
    "    def deal_one(self):\n",
    "        card = self._deck[self.pos]\n",
    "        self.pos += 1\n",
    "        return card\n",
    "    \n",
    "    def burn(self):\n",
    "        self.pos += 1\n",
    "    \n",
    "    def reset(self):\n",
    "        self.pos = 0\n",
    "        self._shuffle()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._deck)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return ''.join([f\"{rank} of {suit}\" for rank, suit in self._deck], '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# bots/action.py\n",
    "\n",
    "from enum import IntEnum\n",
    "\n",
    "class ActionType(IntEnum):\n",
    "    FOLD = 0\n",
    "    CALL = 1\n",
    "    RAISE = 2\n",
    "\n",
    "class Action:\n",
    "    def __init__(self, action_type: ActionType = ActionType.FOLD, bet: int = 0):\n",
    "        self.type = action_type\n",
    "        self.bet = bet\n",
    "\n",
    "    def type_str(self):\n",
    "        if self.type == ActionType.FOLD:\n",
    "            return \"FOLD\"\n",
    "        elif self.type == ActionType.CALL:\n",
    "            return \"CALL\"\n",
    "        elif self.type == ActionType.RAISE:\n",
    "            return \"RAISE\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Action({self.type_str()}, {self.bet})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# evaluation/lookup.py\n",
    "\n",
    "# Copied from https://github.com/keithlee96/pluribus-poker-AI/blob/develop/poker_ai/poker/evaluation/lookup.py\n",
    "# Lookup Table for quick hand evaluation\n",
    "\n",
    "import itertools\n",
    "\n",
    "class LookupTable(object):\n",
    "    \"\"\"\n",
    "    Number of Distinct Hand Values:\n",
    "\n",
    "    Straight Flush   10\n",
    "    Four of a Kind   156      [(13 choose 2) * (2 choose 1)]\n",
    "    Full Houses      156      [(13 choose 2) * (2 choose 1)]\n",
    "    Flush            1277     [(13 choose 5) - 10 straight flushes]\n",
    "    Straight         10\n",
    "    Three of a Kind  858      [(13 choose 3) * (3 choose 1)]\n",
    "    Two Pair         858      [(13 choose 3) * (3 choose 2)]\n",
    "    One Pair         2860     [(13 choose 4) * (4 choose 1)]\n",
    "    High Card      + 1277     [(13 choose 5) - 10 straights]\n",
    "    -------------------------\n",
    "    TOTAL            7462\n",
    "\n",
    "    Here we create a lookup table which maps:\n",
    "        5 card hand's unique prime product => rank in range [1, 7462]\n",
    "\n",
    "    Examples:\n",
    "    * Royal flush (best hand possible)          => 1\n",
    "    * 7-5-4-3-2 unsuited (worst hand possible)  => 7462\n",
    "    \"\"\"\n",
    "\n",
    "    MAX_STRAIGHT_FLUSH = 10\n",
    "    MAX_FOUR_OF_A_KIND = 166\n",
    "    MAX_FULL_HOUSE = 322\n",
    "    MAX_FLUSH = 1599\n",
    "    MAX_STRAIGHT = 1609\n",
    "    MAX_THREE_OF_A_KIND = 2467\n",
    "    MAX_TWO_PAIR = 3325\n",
    "    MAX_PAIR = 6185\n",
    "    MAX_HIGH_CARD = 7462\n",
    "\n",
    "    MAX_TO_RANK_CLASS = {\n",
    "        MAX_STRAIGHT_FLUSH: 1,\n",
    "        MAX_FOUR_OF_A_KIND: 2,\n",
    "        MAX_FULL_HOUSE: 3,\n",
    "        MAX_FLUSH: 4,\n",
    "        MAX_STRAIGHT: 5,\n",
    "        MAX_THREE_OF_A_KIND: 6,\n",
    "        MAX_TWO_PAIR: 7,\n",
    "        MAX_PAIR: 8,\n",
    "        MAX_HIGH_CARD: 9,\n",
    "    }\n",
    "\n",
    "    RANK_CLASS_TO_STRING = {\n",
    "        1: \"Straight Flush\",\n",
    "        2: \"Four of a Kind\",\n",
    "        3: \"Full House\",\n",
    "        4: \"Flush\",\n",
    "        5: \"Straight\",\n",
    "        6: \"Three of a Kind\",\n",
    "        7: \"Two Pair\",\n",
    "        8: \"Pair\",\n",
    "        9: \"High Card\",\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Calculates lookup tables\n",
    "        \"\"\"\n",
    "        # create dictionaries\n",
    "        self.flush_lookup = {}\n",
    "        self.unsuited_lookup = {}\n",
    "\n",
    "        # create the lookup table in piecewise fashion\n",
    "        # this will call straights and high cards method,\n",
    "        # we reuse some of the bit sequences\n",
    "        self.flushes()\n",
    "        self.multiples()\n",
    "\n",
    "    def flushes(self):\n",
    "        \"\"\"\n",
    "        Straight flushes and flushes.\n",
    "\n",
    "        Lookup is done on 13 bit integer (2^13 > 7462):\n",
    "        xxxbbbbb bbbbbbbb => integer hand index\n",
    "        \"\"\"\n",
    "\n",
    "        # straight flushes in rank order\n",
    "        straight_flushes = [\n",
    "            7936,  # int('0b1111100000000', 2), # royal flush\n",
    "            3968,  # int('0b111110000000', 2),\n",
    "            1984,  # int('0b11111000000', 2),\n",
    "            992,  # int('0b1111100000', 2),\n",
    "            496,  # int('0b111110000', 2),\n",
    "            248,  # int('0b11111000', 2),\n",
    "            124,  # int('0b1111100', 2),\n",
    "            62,  # int('0b111110', 2),\n",
    "            31,  # int('0b11111', 2),\n",
    "            4111,  # int('0b1000000001111', 2) # 5 high\n",
    "        ]\n",
    "\n",
    "        # now we'll dynamically generate all the other\n",
    "        # flushes (including straight flushes)\n",
    "        flushes = []\n",
    "        gen = self.get_lexographically_next_bit_sequence(int(\"0b11111\", 2))\n",
    "\n",
    "        # 1277 = number of high cards\n",
    "        # 1277 + len(str_flushes) is number of hands with all cards unique rank\n",
    "        for i in range(1277 + len(straight_flushes) - 1):\n",
    "            # we also iterate over SFs\n",
    "            # pull the next flush pattern from our generator\n",
    "            f = next(gen)\n",
    "\n",
    "            # if this flush matches perfectly any\n",
    "            # straight flush, do not add it\n",
    "            notSF = True\n",
    "            for sf in straight_flushes:\n",
    "                # if f XOR sf == 0, then bit pattern\n",
    "                # is same, and we should not add\n",
    "                if not f ^ sf:\n",
    "                    notSF = False\n",
    "\n",
    "            if notSF:\n",
    "                flushes.append(f)\n",
    "\n",
    "        # we started from the lowest straight pattern, now we want to start\n",
    "        # ranking from the most powerful hands, so we reverse\n",
    "        flushes.reverse()\n",
    "        # now add to the lookup map:\n",
    "        # start with straight flushes and the rank of 1\n",
    "        # since it is the best hand in poker\n",
    "        # rank 1 = Royal Flush!\n",
    "        self._fill_in_lookup_table(\n",
    "            rank_init=1,\n",
    "            rankbits_list=straight_flushes,\n",
    "            lookup_table=self.flush_lookup)\n",
    "        # we start the counting for flushes on max full house, which\n",
    "        # is the worst rank that a full house can have (2,2,2,3,3)\n",
    "        self._fill_in_lookup_table(\n",
    "            rank_init=LookupTable.MAX_FULL_HOUSE + 1,\n",
    "            rankbits_list=flushes,\n",
    "            lookup_table=self.flush_lookup)\n",
    "        # we can reuse these bit sequences for straights\n",
    "        # and high cards since they are inherently related\n",
    "        # and differ only by context\n",
    "        self.straight_and_highcards(straight_flushes, flushes)\n",
    "\n",
    "    def _fill_in_lookup_table(self, rank_init, rankbits_list, lookup_table):\n",
    "        \"\"\"Iterate over rankbits and fill in lookup_table\"\"\"\n",
    "        rank = rank_init\n",
    "        for rb in rankbits_list:\n",
    "            prime_product = EvaluationCard.prime_product_from_rankbits(rb)\n",
    "            lookup_table[prime_product] = rank\n",
    "            rank += 1\n",
    "\n",
    "    def straight_and_highcards(self, straights, highcards):\n",
    "        \"\"\"\n",
    "        Unique five card sets. Straights and highcards.\n",
    "\n",
    "        Reuses bit sequences from flush calculations.\n",
    "        \"\"\"\n",
    "        self._fill_in_lookup_table(\n",
    "            rank_init=LookupTable.MAX_FLUSH + 1,\n",
    "            rankbits_list=straights,\n",
    "            lookup_table=self.unsuited_lookup)\n",
    "        self._fill_in_lookup_table(\n",
    "            rank_init=LookupTable.MAX_PAIR + 1,\n",
    "            rankbits_list=highcards,\n",
    "            lookup_table=self.unsuited_lookup)\n",
    "\n",
    "    def multiples(self):\n",
    "        \"\"\"\n",
    "        Pair, Two Pair, Three of a Kind, Full House, and 4 of a Kind.\n",
    "        \"\"\"\n",
    "        backwards_ranks = list(range(len(EvaluationCard.INT_RANKS) - 1, -1, -1))\n",
    "\n",
    "        # 1) Four of a Kind\n",
    "        rank = LookupTable.MAX_STRAIGHT_FLUSH + 1\n",
    "\n",
    "        # for each choice of a set of four rank\n",
    "        for i in backwards_ranks:\n",
    "\n",
    "            # and for each possible kicker rank\n",
    "            kickers = backwards_ranks[:]\n",
    "            kickers.remove(i)\n",
    "            for k in kickers:\n",
    "                product = EvaluationCard.PRIMES[i] ** 4 * EvaluationCard.PRIMES[k]\n",
    "                self.unsuited_lookup[product] = rank\n",
    "                rank += 1\n",
    "\n",
    "        # 2) Full House\n",
    "        rank = LookupTable.MAX_FOUR_OF_A_KIND + 1\n",
    "\n",
    "        # for each three of a kind\n",
    "        for i in backwards_ranks:\n",
    "\n",
    "            # and for each choice of pair rank\n",
    "            pairranks = backwards_ranks[:]\n",
    "            pairranks.remove(i)\n",
    "            for pr in pairranks:\n",
    "                product = EvaluationCard.PRIMES[i] ** 3 * EvaluationCard.PRIMES[pr] ** 2\n",
    "                self.unsuited_lookup[product] = rank\n",
    "                rank += 1\n",
    "\n",
    "        # 3) Three of a Kind\n",
    "        rank = LookupTable.MAX_STRAIGHT + 1\n",
    "\n",
    "        # pick three of one rank\n",
    "        for r in backwards_ranks:\n",
    "\n",
    "            kickers = backwards_ranks[:]\n",
    "            kickers.remove(r)\n",
    "            gen = itertools.combinations(kickers, 2)\n",
    "\n",
    "            for kickers in gen:\n",
    "\n",
    "                c1, c2 = kickers\n",
    "                product = EvaluationCard.PRIMES[r] ** 3 * EvaluationCard.PRIMES[c1] * EvaluationCard.PRIMES[c2]\n",
    "                self.unsuited_lookup[product] = rank\n",
    "                rank += 1\n",
    "\n",
    "        # 4) Two Pair\n",
    "        rank = LookupTable.MAX_THREE_OF_A_KIND + 1\n",
    "\n",
    "        tpgen = itertools.combinations(backwards_ranks, 2)\n",
    "        for tp in tpgen:\n",
    "\n",
    "            pair1, pair2 = tp\n",
    "            kickers = backwards_ranks[:]\n",
    "            kickers.remove(pair1)\n",
    "            kickers.remove(pair2)\n",
    "            for kicker in kickers:\n",
    "\n",
    "                product = (\n",
    "                    EvaluationCard.PRIMES[pair1] ** 2\n",
    "                    * EvaluationCard.PRIMES[pair2] ** 2\n",
    "                    * EvaluationCard.PRIMES[kicker]\n",
    "                )\n",
    "                self.unsuited_lookup[product] = rank\n",
    "                rank += 1\n",
    "\n",
    "        # 5) Pair\n",
    "        rank = LookupTable.MAX_TWO_PAIR + 1\n",
    "\n",
    "        # choose a pair\n",
    "        for pairrank in backwards_ranks:\n",
    "\n",
    "            kickers = backwards_ranks[:]\n",
    "            kickers.remove(pairrank)\n",
    "            kgen = itertools.combinations(kickers, 3)\n",
    "\n",
    "            for kickers in kgen:\n",
    "\n",
    "                k1, k2, k3 = kickers\n",
    "                product = (\n",
    "                    EvaluationCard.PRIMES[pairrank] ** 2\n",
    "                    * EvaluationCard.PRIMES[k1]\n",
    "                    * EvaluationCard.PRIMES[k2]\n",
    "                    * EvaluationCard.PRIMES[k3]\n",
    "                )\n",
    "                self.unsuited_lookup[product] = rank\n",
    "                rank += 1\n",
    "\n",
    "    def write_table_to_disk(self, table, filepath):\n",
    "        \"\"\"\n",
    "        Writes lookup table to disk\n",
    "        \"\"\"\n",
    "        with open(filepath, \"w\") as f:\n",
    "            for prime_prod, rank in table.iteritems():\n",
    "                f.write(str(prime_prod) + \",\" + str(rank) + \"\\n\")\n",
    "\n",
    "    def get_lexographically_next_bit_sequence(self, bits):\n",
    "        \"\"\"\n",
    "        Bit hack from here:\n",
    "        http://www-graphics.stanford.edu/~seander/bithacks.html#NextBitPermutation\n",
    "\n",
    "        Generator even does this in poker order rank\n",
    "        so no need to sort when done! Perfect.\n",
    "        \"\"\"\n",
    "        t = int((bits | (bits - 1))) + 1\n",
    "        next = t | ((int(((t & -t) / (bits & -bits))) >> 1) - 1)\n",
    "        yield next\n",
    "        while True:\n",
    "            t = (next | (next - 1)) + 1\n",
    "            next = t | ((((t & -t) // (next & -next)) >> 1) - 1)\n",
    "            yield next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# evaluation/card.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Card:\n",
    "    _INT_RANK_TO_STR = {\n",
    "        0: \"Two\",\n",
    "        1: \"Three\",\n",
    "        2: \"Four\",\n",
    "        3: \"Five\",\n",
    "        4: \"Six\",\n",
    "        5: \"Seven\",\n",
    "        6: \"Eight\",\n",
    "        7: \"Nine\",\n",
    "        8: \"Ten\",\n",
    "        9: \"Jack\",\n",
    "        10: \"Queen\",\n",
    "        11: \"King\",\n",
    "        12: \"Ace\"\n",
    "    }\n",
    "\n",
    "    _INT_SUIT_TO_STR = {\n",
    "        1: \"Spades\",\n",
    "        2: \"Hearts\",\n",
    "        3: \"Diamonds\",\n",
    "        4: \"Clubs\"\n",
    "    }\n",
    "    \n",
    "    def __init__(self, card, from_encode=False):\n",
    "        if from_encode:\n",
    "            self._card = np.array([card % 13, card // 13 + 1])\n",
    "        else:\n",
    "            self._card = card\n",
    "\n",
    "    def __str__(self):\n",
    "        rank = self._INT_RANK_TO_STR[self._card[0]]\n",
    "        suit = self._INT_SUIT_TO_STR[self._card[1]]\n",
    "        return f\"{rank} of {suit}\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        rank = self._INT_RANK_TO_STR[self._card[0]]\n",
    "        suit = self._INT_SUIT_TO_STR[self._card[1]]\n",
    "        return f\"{rank} of {suit}\"\n",
    "\n",
    "    def rank(self):\n",
    "        return self._card[0]\n",
    "\n",
    "    def suit(self):\n",
    "        return self._INT_SUIT_TO_STR[self._card[1]]\n",
    "    \n",
    "    def encode(self):\n",
    "        return int(self._card[0] + 13 * (self._card[1] - 1))\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self._card == other._card\n",
    "    \n",
    "    def to_numpy(self):\n",
    "        return np.array(self._card).astype(int)\n",
    "\n",
    "    def get_eval_card(self):\n",
    "        return EvaluationCard.new(self.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# evaluation/evaluate.py\n",
    "\n",
    "# Copied from https://github.com/keithlee96/pluribus-poker-AI/blob/develop/poker_ai/poker/evaluation/evaluator.py\n",
    "import itertools\n",
    "\n",
    "\n",
    "class Evaluator(object):\n",
    "    \"\"\"\n",
    "    Evaluates hand strengths using a variant of Cactus Kev's algorithm:\n",
    "    http://suffe.cool/poker/evaluator.html\n",
    "\n",
    "    I make considerable optimizations in terms of speed and memory usage,\n",
    "    in fact the lookup table generation can be done in under a second and\n",
    "    consequent evaluations are very fast. Won't beat C, but very fast as\n",
    "    all calculations are done with bit arithmetic and table lookups.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.table = LookupTable()\n",
    "\n",
    "        self.hand_size_map = {5: self._five, 6: self._six, 7: self._seven}\n",
    "\n",
    "    def evaluate(self, cards, board):\n",
    "        \"\"\"\n",
    "        This is the function that the user calls to get a hand rank.\n",
    "\n",
    "        Supports empty board, etc very flexible. No input validation\n",
    "        because that's cycles!\n",
    "        \"\"\"\n",
    "        all_cards = [int(c) for c in cards + board]\n",
    "        return self.hand_size_map[len(all_cards)](all_cards)\n",
    "\n",
    "    def _five(self, cards):\n",
    "        \"\"\"\n",
    "        Performs an evalution given cards in integer form, mapping them to\n",
    "        a rank in the range [1, 7462], with lower ranks being more powerful.\n",
    "\n",
    "        Variant of Cactus Kev's 5 card evaluator, though I saved a lot of memory\n",
    "        space using a hash table and condensing some of the calculations.\n",
    "        \"\"\"\n",
    "        # if flush\n",
    "        if cards[0] & cards[1] & cards[2] & cards[3] & cards[4] & 0xF000:\n",
    "            handOR = (cards[0] | cards[1] | cards[2] | cards[3] | cards[4]) >> 16\n",
    "            prime = EvaluationCard.prime_product_from_rankbits(handOR)\n",
    "            return self.table.flush_lookup[prime]\n",
    "\n",
    "        # otherwise\n",
    "        else:\n",
    "            prime = EvaluationCard.prime_product_from_hand(cards)\n",
    "            return self.table.unsuited_lookup[prime]\n",
    "\n",
    "    def _six(self, cards):\n",
    "        \"\"\"\n",
    "        Performs five_card_eval() on all (6 choose 5) = 6 subsets\n",
    "        of 5 cards in the set of 6 to determine the best ranking,\n",
    "        and returns this ranking.\n",
    "        \"\"\"\n",
    "        minimum = LookupTable.MAX_HIGH_CARD\n",
    "\n",
    "        all5cardcombobs = itertools.combinations(cards, 5)\n",
    "        for combo in all5cardcombobs:\n",
    "\n",
    "            score = self._five(combo)\n",
    "            if score < minimum:\n",
    "                minimum = score\n",
    "\n",
    "        return minimum\n",
    "\n",
    "    def _seven(self, cards):\n",
    "        \"\"\"\n",
    "        Performs five_card_eval() on all (7 choose 5) = 21 subsets\n",
    "        of 5 cards in the set of 7 to determine the best ranking,\n",
    "        and returns this ranking.\n",
    "        \"\"\"\n",
    "        minimum = LookupTable.MAX_HIGH_CARD\n",
    "\n",
    "        all5cardcombobs = itertools.combinations(cards, 5)\n",
    "        for combo in all5cardcombobs:\n",
    "\n",
    "            score = self._five(combo)\n",
    "            if score < minimum:\n",
    "                minimum = score\n",
    "\n",
    "        return minimum\n",
    "\n",
    "    def get_rank_class(self, hr):\n",
    "        \"\"\"Returns the class of hand from the hand hand_rank from evaluate.\"\"\"\n",
    "        if hr >= 0 and hr <= LookupTable.MAX_STRAIGHT_FLUSH:\n",
    "            c = LookupTable.MAX_TO_RANK_CLASS[LookupTable.MAX_STRAIGHT_FLUSH]\n",
    "        elif hr <= LookupTable.MAX_FOUR_OF_A_KIND:\n",
    "            c = LookupTable.MAX_TO_RANK_CLASS[LookupTable.MAX_FOUR_OF_A_KIND]\n",
    "        elif hr <= LookupTable.MAX_FULL_HOUSE:\n",
    "            c = LookupTable.MAX_TO_RANK_CLASS[LookupTable.MAX_FULL_HOUSE]\n",
    "        elif hr <= LookupTable.MAX_FLUSH:\n",
    "            c = LookupTable.MAX_TO_RANK_CLASS[LookupTable.MAX_FLUSH]\n",
    "        elif hr <= LookupTable.MAX_STRAIGHT:\n",
    "            c = LookupTable.MAX_TO_RANK_CLASS[LookupTable.MAX_STRAIGHT]\n",
    "        elif hr <= LookupTable.MAX_THREE_OF_A_KIND:\n",
    "            c = LookupTable.MAX_TO_RANK_CLASS[LookupTable.MAX_THREE_OF_A_KIND]\n",
    "        elif hr <= LookupTable.MAX_TWO_PAIR:\n",
    "            c = LookupTable.MAX_TO_RANK_CLASS[LookupTable.MAX_TWO_PAIR]\n",
    "        elif hr <= LookupTable.MAX_PAIR:\n",
    "            c = LookupTable.MAX_TO_RANK_CLASS[LookupTable.MAX_PAIR]\n",
    "        elif hr <= LookupTable.MAX_HIGH_CARD:\n",
    "            c = LookupTable.MAX_TO_RANK_CLASS[LookupTable.MAX_HIGH_CARD]\n",
    "        else:\n",
    "            raise Exception(\"Inavlid hand rank, cannot return rank class\")\n",
    "        return c\n",
    "\n",
    "    def class_to_string(self, class_int):\n",
    "        \"\"\"\n",
    "        Converts the integer class hand score into a human-readable string.\n",
    "        \"\"\"\n",
    "        return LookupTable.RANK_CLASS_TO_STRING[class_int]\n",
    "\n",
    "    def get_five_card_rank_percentage(self, hand_rank):\n",
    "        \"\"\"\n",
    "        Scales the hand rank score to the [0.0, 1.0] range.\n",
    "        \"\"\"\n",
    "        return float(hand_rank) / float(LookupTable.MAX_HIGH_CARD)\n",
    "\n",
    "    def hand_summary(self, board, hands):\n",
    "        \"\"\"\n",
    "        Gives a sumamry of the hand with ranks as time proceeds.\n",
    "\n",
    "        Requires that the board is in chronological order for the\n",
    "        analysis to make sense.\n",
    "        \"\"\"\n",
    "\n",
    "        assert len(board) == 5, \"Invalid board length\"\n",
    "        for hand in hands:\n",
    "            assert len(hand) == 2, \"Inavlid hand length\"\n",
    "\n",
    "        line_length = 10\n",
    "        stages = [\"FLOP\", \"TURN\", \"RIVER\"]\n",
    "\n",
    "        for i in range(len(stages)):\n",
    "            line = \"=\" * line_length\n",
    "            print(f\"{line} {stages[i]} {line}\")\n",
    "\n",
    "            best_rank = 7463  # rank one worse than worst hand\n",
    "            winners = []\n",
    "            for player, hand in enumerate(hands):\n",
    "\n",
    "                # evaluate current board position\n",
    "                rank = self.evaluate(hand, board[: (i + 3)])\n",
    "                rank_class = self.get_rank_class(rank)\n",
    "                class_string = self.class_to_string(rank_class)\n",
    "                percentage = 1.0 - self.get_five_card_rank_percentage(\n",
    "                    rank\n",
    "                )  # higher better here\n",
    "                print(\n",
    "                    f\"Player {player + 1} hand = {class_string}, percentage rank among all hands = {percentage}\"\n",
    "                )\n",
    "\n",
    "                # detect winner\n",
    "                if rank == best_rank:\n",
    "                    winners.append(player)\n",
    "                    best_rank = rank\n",
    "                elif rank < best_rank:\n",
    "                    winners = [player]\n",
    "                    best_rank = rank\n",
    "\n",
    "            # if we're not on the river\n",
    "            if i != stages.index(\"RIVER\"):\n",
    "                if len(winners) == 1:\n",
    "                    print(f\"Player {winners[0] + 1} hand is currently winning.\\n\")\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"Players {[x + 1 for x in winners]} are tied for the lead.\\n\"\n",
    "                    )\n",
    "\n",
    "            # otherwise on all other streets\n",
    "            else:\n",
    "                hand_result = self.class_to_string(\n",
    "                    self.get_rank_class(self.evaluate(hands[winners[0]], board))\n",
    "                )\n",
    "                print()\n",
    "                print(f\"{line} HAND OVER {line}\")\n",
    "                if len(winners) == 1:\n",
    "                    print(\n",
    "                        f\"Player {winners[0] + 1} is the winner with a {hand_result}\\n\"\n",
    "                    )\n",
    "                else:\n",
    "                    print(f\"Players {winners} tied for the win with a {hand_result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# state/state.py\n",
    "\n",
    "import torch\n",
    "import copy\n",
    "\n",
    "\n",
    "START_MONEY = 10000\n",
    "\n",
    "class Round(IntEnum):\n",
    "    PREFLOP = 0\n",
    "    FLOP = 1\n",
    "    TURN = 2\n",
    "    RIVER = 3\n",
    "\n",
    "class BotState:\n",
    "    def __init__(self) -> None:\n",
    "        self._play = True\n",
    "        self._money = START_MONEY\n",
    "        self._total_bet = 0\n",
    "        self._current_bet = 0\n",
    "\n",
    "    @property\n",
    "    def round_money(self) -> int:\n",
    "        return self._money + self._current_bet\n",
    "    @property\n",
    "    def play(self) -> bool:\n",
    "        return self._play\n",
    "    \n",
    "    @play.setter\n",
    "    def play(self, value: bool) -> None:\n",
    "        self._play = value\n",
    "\n",
    "    @property\n",
    "    def money(self) -> int:\n",
    "        return self._money\n",
    "    \n",
    "    @money.setter\n",
    "    def money(self, value: int) -> None:\n",
    "        self._money = value\n",
    "    \n",
    "    @property\n",
    "    def total_bet(self) -> int:\n",
    "        return self._total_bet\n",
    "\n",
    "    @total_bet.setter\n",
    "    def total_bet(self, value: int) -> None:\n",
    "        self._total_bet = value\n",
    "    \n",
    "    @property\n",
    "    def current_bet(self) -> int:\n",
    "        return self._current_bet\n",
    "    \n",
    "    @current_bet.setter\n",
    "    def current_bet(self, value: int) -> None:\n",
    "        self._current_bet = value \n",
    "    \n",
    "    def build_stack(self) -> torch.Tensor:\n",
    "        return torch.Tensor([self.money, self.total_bet, self.current_bet]) / START_MONEY\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return f\"BotState(play={self.play}, money={self.money}, total_bet={self.total_bet}, current_bet={self.current_bet})\"\n",
    "\n",
    "class MiniState:\n",
    "    \"\"\"\n",
    "    Mini state of the game.\n",
    "    Tracks:\n",
    "        - table\n",
    "        - history of bets\n",
    "        - round\n",
    "        - current player\n",
    "    \"\"\"\n",
    "    def __init__(self, table, players_left, n_players, max_round_size) -> None:\n",
    "        self.table = table # cards on table\n",
    "\n",
    "        self.action_history = [] # List of Actions\n",
    "\n",
    "        self.n_players = n_players\n",
    "        \n",
    "        # We know the round is over when folded + called = players_left\n",
    "        self.players_left = players_left\n",
    "        self.folded = 0\n",
    "        self.other = 0\n",
    "        self.num_raises = 0\n",
    "\n",
    "        self.pot = 0\n",
    "        self.top_bet = 0\n",
    "        self.max_round_size = max_round_size\n",
    "\n",
    "    def encode_single_action(self, action) -> np.array:\n",
    "        \"\"\"Encodes the action history (formatted for BrownNet)\"\"\"\n",
    "        if action.type == ActionType.FOLD: return np.array([0])\n",
    "        if action.type == ActionType.CALL: return np.array([0])\n",
    "        if action.type == ActionType.RAISE: return np.array([action.bet])\n",
    "            \n",
    "    def encode_action(self) -> np.array:\n",
    "        \"\"\"Encodes the action history\"\"\"\n",
    "        return np.array([self.encode_single_action(action) for action in self.action_history] + [np.zeros(1) for _ in range(self.max_round_size - len(self.action_history))])\n",
    "\n",
    "    def update(self, action: Action, bots, curr_player, global_pot, blind=False) -> None:\n",
    "        \"\"\"Update the state of the game with the given action\"\"\"\n",
    "\n",
    "        if action.type == ActionType.CALL: \n",
    "            difference = action.bet - bots[curr_player].current_bet\n",
    "            bots[curr_player].current_bet = action.bet\n",
    "            bots[curr_player].total_bet += difference\n",
    "            bots[curr_player].money -= difference\n",
    "            action.bet = difference / global_pot\n",
    "            self.pot += difference\n",
    "        elif action.type == ActionType.RAISE:\n",
    "            bots[curr_player].current_bet += action.bet\n",
    "            bots[curr_player].total_bet += action.bet\n",
    "            bots[curr_player].money -= action.bet\n",
    "            self.top_bet = max(self.top_bet, bots[curr_player].current_bet)\n",
    "            self.pot += action.bet\n",
    "            action.bet /= global_pot  \n",
    "        \n",
    "        self.action_history.append(action)\n",
    "\n",
    "        # blinds do not count as part of the round\n",
    "        if blind:\n",
    "            return\n",
    "\n",
    "        if action.type == ActionType.FOLD: \n",
    "            bots[curr_player].play = False\n",
    "            self.folded += 1\n",
    "        elif action.type == ActionType.CALL: self.other += 1\n",
    "        elif action.type == ActionType.RAISE: self.update_backlog()\n",
    "    \n",
    "    def update_backlog(self) -> None:\n",
    "        \"\"\"Reset folded and called players\"\"\"\n",
    "        self.players_left -= self.folded\n",
    "        self.folded = 0\n",
    "        self.other = 1\n",
    "        self.num_raises += 1\n",
    "    \n",
    "    def end_round(self) -> bool:\n",
    "        \"\"\"Called every time a player makes an action to check if the round is over\"\"\"\n",
    "        return self.other + self.folded == self.players_left \n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        build_str = f\"MiniState: pot={self.pot}, top_bet={self.top_bet}\\n\"\n",
    "        build_str += f\"Table: {self.table}\\n\"\n",
    "        build_str += f\"Action history: \\n\"\n",
    "        for i, action in enumerate(self.action_history):\n",
    "            build_str += f\"Player {(self.start_player + i) % self.total_players}: {bot.__str__()}\\n\"\n",
    "        \n",
    "        return build_str\n",
    "\n",
    "class State:\n",
    "    \"\"\"\n",
    "    State of the game\n",
    "        - could have mini state for each round\n",
    "            - field for invidiual mini state (preflop)\n",
    "            - consider each player's bets\n",
    "        - pot\n",
    "        - could have history of actions\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "        n_players=6,\n",
    "        num_rounds=2, # 2 for FHP\n",
    "        max_round_size=7 # 7 for FHP\n",
    "    ) -> None:\n",
    "        self.pot = 0\n",
    "        self.start_player = np.random.randint(0, n_players)\n",
    "        self.curr_player = self.start_player\n",
    "        self.num_rounds = num_rounds\n",
    "        self.max_round_size = max_round_size\n",
    "\n",
    "        self.total_players = n_players\n",
    "        self.active = n_players\n",
    "\n",
    "        self.bots = [BotState() for _ in range(n_players)]\n",
    "\n",
    "        self.table = []\n",
    "        self.mini_states = [MiniState(self.table, self.active, self.total_players, self.max_round_size)]\n",
    "        self.round = Round.PREFLOP\n",
    "        self.deck = Deck()\n",
    "        self.deck.reset()\n",
    "\n",
    "        # little\n",
    "        self.mini_states[-1].update(Action(ActionType.RAISE, 50), self.bots, self.curr_player, 150, blind=True)\n",
    "        self.curr_player = (self.curr_player + 1) % self.total_players\n",
    "        self.pot += 50\n",
    "\n",
    "        # big\n",
    "        self.mini_states[-1].update(Action(ActionType.RAISE, 100), self.bots, self.curr_player, 150, blind=True)\n",
    "        self.curr_player = (self.curr_player + 1) % self.total_players\n",
    "        self.pot += 100\n",
    "\n",
    "        self.depth = 0\n",
    "\n",
    "    def board_size(self):\n",
    "        return self.num_rounds + 1\n",
    "\n",
    "    def finish_round(self):\n",
    "        \"\"\"Called at end of each round. Updates the pot and creates a new mini state\"\"\"\n",
    "        self.reset_money()\n",
    "\n",
    "        if self.round == self.num_rounds - 1:\n",
    "            return\n",
    "\n",
    "        if self.round == Round.PREFLOP:\n",
    "            self.table = self.deck.deal(3)\n",
    "            self.round += 1\n",
    "        elif self.round == Round.FLOP:\n",
    "            self.table += self.deck.deal(1)\n",
    "            self.round += 1\n",
    "        elif self.round == Round.TURN:\n",
    "            self.table += self.deck.deal(1)\n",
    "            self.round += 1\n",
    "\n",
    "        self.mini_states.append(MiniState(self.table, self.active, self.total_players, self.max_round_size))\n",
    "            \n",
    "        self.curr_player = self.start_player\n",
    "\n",
    "    def deal_player(self):\n",
    "        return self.deck.deal_one()\n",
    "    \n",
    "    def get_top_bet(self):\n",
    "        return self.mini_states[-1].top_bet\n",
    "\n",
    "    def is_terminal(self) -> bool:\n",
    "        return (self.round == (self.num_rounds - 1)  and self.end_round()) or self.one_player_left() or len(self.mini_states) > self.num_rounds\n",
    "\n",
    "    def one_player_left(self) -> bool:\n",
    "        return sum([bot.play for bot in self.bots]) == 1\n",
    "\n",
    "    def end_round(self) -> bool:\n",
    "        return self.mini_states[-1].end_round()\n",
    "\n",
    "    def to_dict(self):\n",
    "        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        encoded_actions = [torch.Tensor(mini_state.encode_action()).to(device) for mini_state in self.mini_states]\n",
    "        empty_actions = [torch.zeros(self.max_round_size, 1).to(device) for _ in range(self.num_rounds - len(self.mini_states))]\n",
    "        return {\n",
    "            \"h_action\": torch.stack(encoded_actions + empty_actions).view(-1),\n",
    "            # encode cards between 0-51, -1 for unknown\n",
    "            \"cards\": [Card(c).encode() for c in self.table] + [-1 for _ in range(self.board_size() - len(self.table))],\n",
    "        }\n",
    "\n",
    "    def reset_money(self):\n",
    "        for player in self.bots:\n",
    "            player.current_bet = 0\n",
    "    \n",
    "    def next_player(self):\n",
    "        self.curr_player = (self.curr_player + 1) % self.total_players\n",
    "        while not self.bots[self.curr_player].play:\n",
    "            self.curr_player = (self.curr_player + 1) % self.total_players\n",
    "            \n",
    "    def update(self, action: Action):\n",
    "        if action.type == 0: self.active -= 1 # for next mini state\n",
    "        # update state pot with ministate pot difference after update\n",
    "        self.pot -= self.mini_states[-1].pot\n",
    "        self.mini_states[-1].update(action, self.bots, self.curr_player, self.pot + self.mini_states[-1].pot)\n",
    "        self.pot += self.mini_states[-1].pot\n",
    "        self.curr_player = (self.curr_player + 1) % self.total_players\n",
    "\n",
    "        if self.end_round(): self.finish_round()\n",
    "\n",
    "        self.depth += 1\n",
    "\n",
    "    def round_to_str(self):\n",
    "        return [\"PREFLOP\", \"FLOP\", \"TURN\", \"RIVER\"][int(self.round)]\n",
    "\n",
    "    def print_history(self):\n",
    "        print(\"State history:\")\n",
    "        for i, mini_state in enumerate(self.mini_states):\n",
    "            print(f\"Round {i}: {mini_state.__str__()}\")\n",
    "            \n",
    "    def __str__(self) -> str:\n",
    "        build_str = f\"Sate: pot={self.pot}, round={self.round_to_str()}\\n\"\n",
    "        for i, bot in enumerate(self.bots):\n",
    "            build_str += f\"Player {i}: {bot.__str__()}\\n\"\n",
    "        \n",
    "        build_str += f\"Table: {self.table}\\n\"\n",
    "        build_str += f\"Top bet: {self.get_top_bet()}\\n\"\n",
    "        return build_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# cfr/dataset.py\n",
    "# cfr/wprollout.py\n",
    "# cfr/brown_net.py\n",
    "# cfr/deep_cfr.py\n",
    "# + extras for experimentation\n",
    "\n",
    "# Apply deep mccfr minimization\n",
    "# Allow neural network to learn abstractions of the game through embeddings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Any\n",
    "import copy\n",
    "import math\n",
    "    \n",
    "def aggregate_bets_fhp(state, action_dist):\n",
    "    \"\"\"\n",
    "    Default aggregation of bets for Flop Hold'em Poker\n",
    "    \"\"\"\n",
    "    if state.mini_states[-1].num_raises >= 3:\n",
    "        new_dist = torch.zeros(action_dist.shape)#.to(device)\n",
    "        new_dist[0] = action_dist[0]\n",
    "        new_dist[1] = action_dist[1:].sum()\n",
    "        return new_dist\n",
    "\n",
    "    return action_dist\n",
    "        \n",
    "class ValueDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, states = [], hands = [], values = [], T = []):\n",
    "        self.states = states\n",
    "        self.hands = hands\n",
    "        self.values = values\n",
    "        self.T = T\n",
    "\n",
    "    def append(self, x, value, t):\n",
    "        self.states.append(x)\n",
    "        self.values.append(value)\n",
    "        self.T.append(t)\n",
    "    \n",
    "    def setup(self):\n",
    "        self.values = [torch.Tensor(x).cpu() for x in self.values]\n",
    "        self.values = torch.stack(self.values)\n",
    "\n",
    "    def reset(self):\n",
    "        self.values = self.values.cpu().tolist()\n",
    "\n",
    "    def save(self, save_path=\"/kaggle/working/value_dataset.pt\"):\n",
    "        data = {\n",
    "            'states': self.states,\n",
    "            'hands': self.hands,\n",
    "            'values': self.values,\n",
    "            'T': self.T\n",
    "        }\n",
    "        torch.save(data, save_path)\n",
    "\n",
    "    def load(self, load_path=\"/kaggle/input/M_Vp/value_dataset.pt\"):\n",
    "        data = torch.load(load_path, weights_only=False)\n",
    "        self.states = data['states']\n",
    "        self.hands = data['hands']\n",
    "        self.values = data['values']\n",
    "        self.T = data['T']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.states)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.states[idx], self.values[idx], self.T[idx]\n",
    "\n",
    "class PolicyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, states = [], hands = [], policies = [], T = []):\n",
    "        self.states = states\n",
    "        self.hands = hands\n",
    "        self.policies = policies\n",
    "        self.T = T\n",
    "\n",
    "    def append(self, x, policy, t):\n",
    "        self.states.append(x)\n",
    "        self.policies.append(policy)\n",
    "        self.T.append(t)\n",
    "    \n",
    "    def setup(self):\n",
    "        self.policies = [torch.Tensor(x).cpu() for x in self.policies]\n",
    "        self.policies = torch.stack(self.policies)\n",
    "\n",
    "    def reset(self):\n",
    "        self.policies = self.policies.cpu().tolist()\n",
    "\n",
    "    def save(self, save_path=\"/kaggle/working/policy_dataset.pt\"):\n",
    "        data = {\n",
    "            'states': self.states,\n",
    "            'hands': self.hands,\n",
    "            'policies': self.policies,\n",
    "            'T': self.T\n",
    "        }\n",
    "        torch.save(data, save_path)\n",
    "\n",
    "    def load(self, load_path=\"/kaggle/input/M_Vp/policy_dataset.pt\"):\n",
    "        data = torch.load(load_path, weights_only=False)\n",
    "        self.states = data['states']\n",
    "        self.hands = data['hands']\n",
    "        self.policies = data['policies']\n",
    "        self.T = data['T']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.states)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.states[idx], self.policies[idx], self.T[idx]\n",
    "\n",
    "class WpRollout:\n",
    "    def __init__(self, preflop_win_rates, preflop_tie_rates):\n",
    "        self.preflop_win_rates = torch.Tensor(preflop_win_rates)\n",
    "        self.preflop_tie_rates = torch.Tensor(preflop_tie_rates)\n",
    "        self.flop_win_rates = None\n",
    "        self.flop_tie_rates = None\n",
    "        self.player = None\n",
    "        self.index = None\n",
    "\n",
    "    def fix(self, p_cards, i):\n",
    "        self.player = i\n",
    "        self.index = self.encode_hand([p_cards[0].encode(), p_cards[1].encode()])\n",
    "        self.p_cards = [c.encode() for c in p_cards]\n",
    "        self.eval_cards = [c.get_eval_card() for c in p_cards]\n",
    "        self.flop_win_rates = None\n",
    "        self.flop_tie_rates = None\n",
    "\n",
    "    def win_rates(self, board, remaining_cards):\n",
    "        win_rates = np.zeros(26 * 51)\n",
    "        tie_rates = np.zeros(26 * 51)\n",
    "        evaluator = Evaluator()\n",
    "        \n",
    "        hand_val = evaluator.evaluate(self.eval_cards, [Card(c).get_eval_card() for c in board])\n",
    "        eval_board = [Card(c).get_eval_card() for c in board]\n",
    "        \n",
    "        remaining_hands = list(itertools.combinations(remaining_cards, 2))\n",
    "        # remaining_hands = [h.sort() for h in remaining_hands] # enforce order\n",
    "\n",
    "        eval_hands = [[Card(c, from_encode=True).get_eval_card() for c in h] for h in remaining_hands]\n",
    "        remaining_vals = np.array([evaluator.evaluate(h, eval_board) for h in eval_hands])\n",
    "\n",
    "        wins = (remaining_vals > hand_val).astype(float)\n",
    "        ties = (remaining_vals == hand_val).astype(float)\n",
    "\n",
    "        encoded_hands = [self.encode_hand(hand) for hand in remaining_hands]\n",
    "\n",
    "        win_rates[encoded_hands] = wins\n",
    "        tie_rates[encoded_hands] = ties\n",
    "\n",
    "        return win_rates, tie_rates \n",
    "            \n",
    "    def compute_flop(self, state: State, player_idx: int):\n",
    "        board = state.deck.simulate_deal(3) if len(state.table) == 0 else state.table\n",
    "        encoded_board = [Card(c).encode() for c in board]\n",
    "        \n",
    "        remaining_cards = [c for c in range(52) if c not in self.p_cards + encoded_board]\n",
    "        self.flop_win_rates, self.flop_tie_rates = self.win_rates(board, remaining_cards)\n",
    "        self.flop_win_rates = torch.Tensor(self.flop_win_rates)\n",
    "        self.flop_tie_rates = torch.Tensor(self.flop_tie_rates)\n",
    "\n",
    "    def encode_hand(self, hand):\n",
    "        return (52 - hand[0]) * (52 - hand[0] - 1) // 2 - hand[1] + hand[0]\n",
    "\n",
    "    def get_wins(self, state, pi):\n",
    "        assert self.index is not None, \"Fix index of WpRollout before getting win rates\"\n",
    "        self.preflop_win_rates = self.preflop_win_rates.to(pi.device)\n",
    "        if state.round == Round.PREFLOP:\n",
    "            return pi * self.preflop_win_rates[self.index]\n",
    "        else:\n",
    "            if self.flop_win_rates is None: self.compute_flop(state, self.player)\n",
    "            return pi * self.flop_win_rates.to(pi.device)\n",
    "    \n",
    "    def get_ties(self, state, pi):\n",
    "        assert self.index is not None, \"Fix index of WpRollout before getting tie rates\"\n",
    "        self.preflop_tie_rates = self.preflop_tie_rates.to(pi.device)\n",
    "\n",
    "        if state.round == Round.PREFLOP:\n",
    "            return pi * self.preflop_tie_rates[self.index]\n",
    "        else:\n",
    "            if self.flop_tie_rates is None: self.compute_flop(state, self.player)\n",
    "            return pi * self.flop_tie_rates.to(pi.device)\n",
    "\n",
    "\n",
    "class FC(nn.Module):\n",
    "    def __init__(self, input_dim: int, output_dim: int):\n",
    "        super(FC, self).__init__()\n",
    "\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.fc(x))\n",
    "\n",
    "class CardEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(CardEmbedding, self).__init__()\n",
    "        self.rank = nn.Embedding(13, dim)\n",
    "        self.suit = nn.Embedding(4, dim)\n",
    "        self.card = nn.Embedding(52, dim)\n",
    "\n",
    "    def forward(self, input):\n",
    "        if input.dim() > 2: \n",
    "            input = input.squeeze()\n",
    "        B, num_cards = input.shape\n",
    "        x = input.view(-1)\n",
    "        valid = x.ge(0).float()\n",
    "        x = x.clamp(min=0)\n",
    "        embs = self.card(x) + self.rank(x // 4) + self.suit(x % 4)\n",
    "        embs = embs * valid.unsqueeze(1) # zero out no card  embeddings\n",
    "        \n",
    "        return embs.view(B, num_cards, -1).sum(1)\n",
    "\n",
    "class BrownNet(nn.Module):\n",
    "    def __init__(self, n_card_types, n_bets, n_actions, dim=64):\n",
    "        super(BrownNet, self).__init__()\n",
    "        self.card_embeddings = nn.ModuleList(\n",
    "            [CardEmbedding(dim) for _ in range(n_card_types)]\n",
    "        )\n",
    "        \n",
    "        self.card1 = nn.Linear(dim * n_card_types, dim)\n",
    "        self.card2 = nn.Linear(dim, dim)\n",
    "        self.card3 = nn.Linear(dim, dim)\n",
    "        \n",
    "        self.bet1 = nn.Linear(n_bets * 2, dim)\n",
    "        self.bet2 = nn.Linear(dim, dim)\n",
    "        \n",
    "        self.comb1 = nn.Linear(2 * dim, dim)\n",
    "        self.comb2 = nn.Linear(dim, dim)\n",
    "        self.comb3 = nn.Linear(dim, dim)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm((dim))\n",
    "        self.action_head = nn.Linear(dim, n_actions)\n",
    "\n",
    "        nn.init.constant_(self.action_head.weight, 0)\n",
    "        nn.init.constant_(self.action_head.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        cards : ( (N x 2), (N x 3) [, (N x 1), (N x 1)] ) # (hole, board, [turn, river])\n",
    "        bets : N x n_bet_feats\n",
    "        \"\"\"\n",
    "        cards = x[\"cards\"]\n",
    "        # bets = torch.cat((x[\"h_action\"][0].squeeze(), x[\"h_action\"][1].squeeze()), dim=-1).squeeze().unsqueeze(0).to(\"cuda\")\n",
    "        bets = x[\"h_action\"].to(\"cuda\")\n",
    "        if bets.dim() < 2: bets = bets.unsqueeze(0)\n",
    "        card_embs = []\n",
    "        for embedding, card_group in zip(self.card_embeddings, cards):\n",
    "            card_embs.append(embedding(card_group))\n",
    "        card_embs = torch.cat(card_embs, dim=-1)\n",
    "\n",
    "        x = F.relu(self.card1(card_embs))\n",
    "        x = F.relu(self.card2(x))\n",
    "        x = F.relu(self.card3(x))\n",
    "\n",
    "\n",
    "        bet_size = bets.clamp(min=0)\n",
    "        bets_occured = bets.ge(0).float()\n",
    "        bet_feats = torch.cat([bet_size, bets_occured], dim=-1)\n",
    "\n",
    "        y = F.relu(self.bet1(bets))\n",
    "        y = F.relu(self.bet2(y) + y)\n",
    "\n",
    "        if y.dim() > 2: y = y.squeeze()\n",
    "\n",
    "        z = torch.cat([x, y], dim=-1)\n",
    "        z = F.relu(self.comb1(z))\n",
    "        z = F.relu(self.comb2(z) + z)\n",
    "        z = F.relu(self.comb3(z) + z)\n",
    "\n",
    "        z = self.layer_norm(z)\n",
    "        return self.action_head(z)\n",
    "\n",
    "class MCCFR():\n",
    "    def __init__(self, \n",
    "        n_players: int = 2, # 6 for standard poker\n",
    "        start_money: int = 10000, \n",
    "        load_ckpt = False, \n",
    "        aggregation_func: Any = aggregate_bets_fhp,\n",
    "        raise_map: np.array = np.array([100]), # action map for raise amounts\n",
    "        exact_map: bool = True, # using exact map or fraction of pot\n",
    "        wp_path: str = \"/kaggle/input/flop-rollouts\"\n",
    "    ):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.bot_hands = []\n",
    "\n",
    "        self.value_net = BrownNet(n_card_types=2, n_bets=7, n_actions=3, dim=64)\n",
    "        self.value_net.to(self.device)\n",
    "\n",
    "        # self.policy_net = BrownNet(n_card_types=2, n_bets=7, n_actions=3, dim=64)\n",
    "        # self.policy_net.to(self.device)\n",
    "        \n",
    "        count = 0\n",
    "        for param in self.value_net.parameters():\n",
    "            count += param.numel()\n",
    "        print(f\"Network with {count} parameters\")\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.value_net.parameters(), lr=1e-3)\n",
    "        # self.policy_optimizer = torch.optim.Adam(self.policy_net.parameters(), lr=1e-3)\n",
    "        \n",
    "        self.bet_money = 0\n",
    "        self.num_players = n_players\n",
    "        \n",
    "        self.decisions = 0\n",
    "        self.questionable = 0\n",
    "\n",
    "        self.load_ckpt = load_ckpt\n",
    "\n",
    "        win_rates = np.load(os.path.join(wp_path, \"win_rates.npy\"))\n",
    "        tie_rates = np.load(os.path.join(wp_path, \"tie_rates.npy\"))\n",
    "\n",
    "        self.wprollout = WpRollout(win_rates, tie_rates)\n",
    "\n",
    "        # Function for aggregating bets using round-based constraints\n",
    "        self.aggregation_func = aggregation_func\n",
    "        self.raise_map = raise_map\n",
    "        self.exact_map = exact_map\n",
    "\n",
    "\n",
    "    def get_eval_cards(self, idx):\n",
    "        card_a = Card(self.bot_hands[idx][0]._card)\n",
    "        card_b = Card(self.bot_hands[idx][1]._card)\n",
    "        return [card_a.get_eval_card(), card_b.get_eval_card()]\n",
    "\n",
    "    def begin_round(self, state):\n",
    "        \"\"\"Deals cards to players and initializes round\"\"\"\n",
    "        \n",
    "        self.bot_hands.clear()\n",
    "        for i in range(self.num_players):\n",
    "            self.bot_hands.append([Card(state.deal_player())])\n",
    "        \n",
    "        for i in range(self.num_players):\n",
    "            self.bot_hands[i].append(Card(state.deal_player()))\n",
    "        \n",
    "        self.decisions = 0\n",
    "        self.questionable = 0\n",
    "\n",
    "    def save_checkpoint(self, sim):\n",
    "        ckpt = {\n",
    "            'sim': sim,\n",
    "            'state': self.value_net.state_dict(),\n",
    "            'optimizer': self.optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(ckpt, '/kaggle/working/value_net.pth')\n",
    "\n",
    "    def save_policy_net(self, sim):\n",
    "        ckpt = {\n",
    "            'sim': sim,\n",
    "            'state': self.policy_net.state_dict(),\n",
    "            'optimizer': self.policy_optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(ckpt, '/kaggle/working/policy_net.pth')\n",
    "\n",
    "    def choice_to_action(self, state, index):\n",
    "        if index == 0: return Action(0, 0)\n",
    "        elif index == 1: return Action(1, state.mini_states[-1].top_bet)\n",
    "        else: \n",
    "            if self.exact_map:\n",
    "                raise_amount = self.raise_map[index - 2]\n",
    "            else:\n",
    "                raise_amount = self.raise_map[index - 2] * state.pot\n",
    "                raise_amount = math.floor(raise_amount)\n",
    "            return Action(2, raise_amount)\n",
    "\n",
    "    def target_policy(self, regret):\n",
    "        \"\"\"\n",
    "        Compute target policy from regret\n",
    "        \"\"\"\n",
    "        target = torch.zeros(regret.shape).to(self.device)\n",
    "        pos_regret = F.relu(regret)\n",
    "        sum_regret = pos_regret.sum()\n",
    "        \n",
    "        if sum_regret < 0:\n",
    "            argmax = torch.argmax(regret)\n",
    "            target[argmax] = 1.\n",
    "            return target\n",
    "        elif sum_regret == 0:\n",
    "            return torch.ones(3).to(regret.device) / 3\n",
    "            \n",
    "        for i in range(len(pos_regret)):\n",
    "            target[i] = pos_regret[i] / sum_regret\n",
    "\n",
    "        return target\n",
    "    \n",
    "    def winner(self, state: State):\n",
    "        \"\"\"\n",
    "        Given a terminal state, return the index of the winning bot\n",
    "        \"\"\"\n",
    "        self.r_bots = [i for i, bot in enumerate(state.bots) if bot.play]\n",
    "\n",
    "        if len(self.r_bots) == 1: return self.r_bots[0]\n",
    "\n",
    "        eval_cards = [self.get_eval_cards(i) for i in self.r_bots]\n",
    "        eval_table = [Card(c).get_eval_card() for c in state.table]\n",
    "        \n",
    "        evals = [Evaluator().evaluate(eval_pair, eval_table) for eval_pair in eval_cards]\n",
    "\n",
    "        win_index = evals.index(min(evals))\n",
    "        return self.r_bots[win_index] # Return index of winning bot\n",
    "\n",
    "    def utility(self, state, bot_idx, win_index):\n",
    "        player = state.bots[bot_idx]\n",
    "        if not player.play: return -player.total_bet\n",
    "        \n",
    "        if bot_idx == win_index: return state.pot - player.total_bet\n",
    "        else: return -player.total_bet\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def traverse(self, state: State, player_idx: int, M_Vp: ValueDataset, t: int):\n",
    "        \"\"\"Rough Training algorithm from Deep MCCFR paper: https://arxiv.org/pdf/1811.00164\n",
    "        if terminal(s) then return u(s)\n",
    "        if s is chance node then \n",
    "            sample a successor s' of s\n",
    "            return traverse(s', player)\n",
    "        if s is a player node then\n",
    "            compute strategy pi(s) for player i\n",
    "            for each action a in pi(s) do\n",
    "                s' = apply(a, s)\n",
    "                u = traverse(s', player)\n",
    "            regret = u - pi(s) * u\n",
    "            M_Vp.append(s, regret, t) # train value net on this\n",
    "            return pi(s) * u\n",
    "        \"\"\"\n",
    "        if not state.bots[state.curr_player].play: # skip folded players\n",
    "            state.next_player()\n",
    "            return self.traverse(state, player_idx, M_Vp, t)\n",
    "\n",
    "        if state.is_terminal(): \n",
    "            return self.utility(state, player_idx, self.winner(state))\n",
    "        elif not state.bots[player_idx].play: # utility of folded player is -total_bet\n",
    "            return -state.bots[player_idx].total_bet\n",
    "        elif state.curr_player != player_idx: # opponent's turn\n",
    "            # With external sampling, we just sample an action using our trained value network \n",
    "            x = state.to_dict()\n",
    "            x[\"cards\"] = [torch.IntTensor(x[\"cards\"]).unsqueeze(0).to(self.device), torch.IntTensor([card.encode() for card in self.bot_hands[(player_idx + 1) % 2]]).unsqueeze(0).to(self.device)]\n",
    "            values = self.value_net(x).squeeze()\n",
    "            \n",
    "            policy = self.target_policy(values)\n",
    "            policy = policy.squeeze()\n",
    "            policy = policy / policy.sum(dim=-1)\n",
    "\n",
    "            agg_policy = self.aggregation_func(state, policy).to(self.device)\n",
    "            \n",
    "            action = torch.distributions.Categorical(agg_policy).sample()\n",
    "            action = self.choice_to_action(state, action)\n",
    "            state.update(action)\n",
    "\n",
    "            return self.traverse(state, player_idx, M_Vp, t)\n",
    "        else: # decision point\n",
    "            self.decisions += 1\n",
    "            x = state.to_dict()\n",
    "            x[\"cards\"] = [torch.IntTensor(x[\"cards\"]).unsqueeze(0).to(self.device), torch.IntTensor([card.encode() for card in self.bot_hands[player_idx]]).unsqueeze(0).to(self.device)]\n",
    "            values = self.value_net(x)\n",
    "            values = values.squeeze()\n",
    "\n",
    "            policy = self.target_policy(values) # calculate policy from values\n",
    "\n",
    "            agg_policy = self.aggregation_func(state, policy).to(self.device)\n",
    "\n",
    "            u = torch.zeros(policy.shape).to(self.device)\n",
    "            for a in range(agg_policy.shape[0]):\n",
    "                if agg_policy[a] < 0.001:\n",
    "                    continue\n",
    "                s_prime = copy.deepcopy(state)\n",
    "                if a > 0:\n",
    "                    act = self.choice_to_action(state, a)\n",
    "                    s_prime.update(act)\n",
    "                    u_raise = self.traverse(s_prime, player_idx, M_Vp, t)\n",
    "                    u[a] = u_raise\n",
    "                else:\n",
    "                    u[a] = -state.bots[player_idx].total_bet\n",
    "\n",
    "            # regret = E[u | a] - E[u | pi]\n",
    "            regret = u - (u * agg_policy).sum()\n",
    "            M_Vp.append(x, regret, t)\n",
    "\n",
    "            return (u * policy).sum()# , total_loss\n",
    "        \n",
    "    def optimize(self, M_Vp: ValueDataset, T: int, steps: int = 4000, batch_size: int = 10000):\n",
    "        self.value_net = BrownNet(n_card_types=2, n_bets=7, n_actions=3, dim=64).to(self.device)\n",
    "        M_Vp.setup()\n",
    "        self.value_net.train()\n",
    "        step = 0\n",
    "        losses = []\n",
    "\n",
    "        loader = torch.utils.data.DataLoader(M_Vp, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # Reinitialize optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.value_net.parameters(), lr=1e-3)\n",
    "        while True:\n",
    "            for x, value, t in loader:\n",
    "                t = t.to(self.device)\n",
    "                t = t.unsqueeze(1).repeat(1, 3) # I might be stupid\n",
    "                self.optimizer.zero_grad()\n",
    "                values = self.value_net(x).squeeze()\n",
    "                loss = torch.mean(t * 2 / T * ((values.squeeze() - value.to(values.device))**2))\n",
    "                losses.append(loss.item())\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.value_net.parameters(), 1.0)\n",
    "                self.optimizer.step()\n",
    "                step += 1\n",
    "                # x[\"h_money\"] = [h.cpu() for h in x[\"h_money\"]]\n",
    "                x[\"h_action\"] = [h.cpu() for h in x[\"h_action\"]]\n",
    "                value = value.cpu()\n",
    "                t = t.cpu()\n",
    "                if step >= steps: \n",
    "                    M_Vp.reset()\n",
    "                    return losses\n",
    "\n",
    "    def optimize_policy(self, M_Pi: PolicyDataset, steps: int, T: int):\n",
    "        self.policy_net = BrownNet(n_card_types=2, n_bets=7, n_actions=3, dim=64).to(self.device)\n",
    "        M_Pi.setup()\n",
    "        self.policy_net.train()\n",
    "        step = 0\n",
    "        losses = []\n",
    "\n",
    "        loader = torch.utils.data.DataLoader(M_Pi, batch_size=10000, shuffle=True) # TODO: return to 10000\n",
    "        \n",
    "        self.policy_optimizer = torch.optim.Adam(self.value_net.parameters(), lr=1e-3)\n",
    "        while True:\n",
    "            for x, target, t in loader:\n",
    "                t = t.to(self.device)\n",
    "                t = t.unsqueeze(1).repeat(1, 3) # I might be stupid\n",
    "                self.policy_optimizer.zero_grad()\n",
    "                policy = self.policy_net(x)\n",
    "                loss = torch.mean(t * 2 / T * ((policy.squeeze() - target.to(policy.device))**2))\n",
    "                losses.append(loss.item())\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.policy_net.parameters(), 1.0)\n",
    "                self.policy_optimizer.step()\n",
    "                step += 1\n",
    "                x[\"h_action\"] = [h.cpu() for h in x[\"h_action\"]]\n",
    "                target = target.cpu()\n",
    "                t = t.cpu()\n",
    "                if step >= steps: \n",
    "                    M_Pi.reset()\n",
    "                    return losses\n",
    "\n",
    "\n",
    "    def remaining_boards(self, board, remaining_cards):\n",
    "        \"\"\"\n",
    "        Returns all possible remaining boards given current board and remaining cards\n",
    "        \"\"\"\n",
    "        return list(itertools.combinations(remaining_cards, 5 - len(board)))\n",
    "\n",
    "    def encode_hand(self, hand):\n",
    "        return (52 - hand[0]) * (52 - hand[0] - 1) // 2 - hand[1] + hand[0]\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def local_best_response(self, pi, state: State, h_i: int):\n",
    "        \"\"\"\n",
    "        Approximate 2-player best response to given policy using local BR algorithm [Lis et al. 2016: https://arxiv.org/pdf/1612.07547]\n",
    "        \n",
    "        Args\n",
    "            pi: torch.Tensor (52^2, 1) -> probability distribution over all possible hands\n",
    "            state: State -> current state of game\n",
    "            h_i: int -> hand index, represented as (card a) * 52 + (card b)\n",
    "        \"\"\"\n",
    "\n",
    "        U = torch.zeros(3) # utility of each action\n",
    "        board = [Card(c).encode() for c in state.table]\n",
    "        hand = [card.encode() for card in self.bot_hands[h_i]]\n",
    "\n",
    "        remaining_cards = set([card for card in range(52) if card not in board + hand])\n",
    "        remaining_hands = list(itertools.combinations(remaining_cards, 2))\n",
    "\n",
    "        encoded_hands = [self.encode_hand(hand) for hand in remaining_hands]\n",
    "        encoded_hands = np.array(encoded_hands)\n",
    "\n",
    "        # renormalize pi\n",
    "        for card in board + hand:\n",
    "            for i in range(52):\n",
    "                if i == card: continue\n",
    "                h = [card, i]\n",
    "                h.sort()\n",
    "                pi[self.encode_hand(h)] = 0\n",
    "        pi = pi / pi.sum()\n",
    "        \n",
    "\n",
    "        wp = self.wprollout.get_wins(state, pi).sum(axis=0)\n",
    "        tp = self.wprollout.get_ties(state, pi).sum(axis=0)\n",
    "        asked = state.bots[(h_i + 1) % 2].total_bet - state.bots[h_i].total_bet\n",
    "        \n",
    "        U[1] = wp * state.pot - (1 - wp) * asked + (tp * state.pot) / 2\n",
    "\n",
    "        action_map = []\n",
    "        for a in range(2, 3):\n",
    "            raise_amount = 100\n",
    "\n",
    "            if raise_amount > state.bots[h_i].money: continue\n",
    "            elif raise_amount + state.bots[h_i].current_bet < state.bots[(h_i + 1) % 2].current_bet * 2: continue\n",
    "\n",
    "            fp = 0\n",
    "            for enc_hand, hand in zip(encoded_hands, remaining_hands):\n",
    "                x = state.to_dict()\n",
    "                x[\"cards\"] = [torch.IntTensor(x[\"cards\"]).unsqueeze(0).to(self.device), torch.IntTensor(hand).unsqueeze(0).to(self.device)]       \n",
    "                values = self.value_net(x).squeeze()\n",
    "                fold_policy = self.target_policy(values)[0]\n",
    "                fp += pi[enc_hand] * fold_policy\n",
    "                pi[enc_hand] *= (1 - fold_policy)\n",
    "            sum_pi = pi.sum()\n",
    "            pi = pi / pi.sum() # renormalize\n",
    "            wp = self.wprollout.get_wins(state, pi).sum(axis=0) # self.wprollout(h_i, state, pi)\n",
    "            tp = self.wprollout.get_ties(state, pi).sum(axis=0) # self.wprollout(h_i, state, pi)\n",
    "            U[a] = fp * state.pot \\\n",
    "                    + (1 - fp) * (wp * (state.pot + raise_amount) - (1 - wp) * (asked + raise_amount)) \\\n",
    "                    + (1 - fp) * (tp * (state.pot + raise_amount)) / 2\n",
    "\n",
    "        if U.max() > 0: return U.argmax(), pi\n",
    "        return 0, pi\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def vs_br(self, state, pi, player_idx):\n",
    "        assert state.total_players == 2, \"Can only approximate local best response for 2-player games\"\n",
    "        \n",
    "        if state.is_terminal(): return -1 * self.utility(state, player_idx, self.winner(state))\n",
    "        elif state.curr_player != player_idx:\n",
    "            action, pi = self.local_best_response(pi, state, (player_idx + 1) % 2)\n",
    "            state.update(self.choice_to_action(state, action))\n",
    "            return self.vs_br(state, pi, player_idx)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                self.value_net.eval()\n",
    "                x = state.to_dict()\n",
    "                x[\"cards\"] = [torch.IntTensor(x[\"cards\"]).unsqueeze(0).to(self.device), torch.IntTensor([card.encode() for card in self.bot_hands[player_idx]]).unsqueeze(0).to(self.device)] \n",
    "                values = self.value_net(x).squeeze()\n",
    "\n",
    "                policy = self.target_policy(values)\n",
    "                assert (policy >= 0).all()\n",
    "                assert torch.abs(policy.sum() - 1) < 0.0001\n",
    "                \n",
    "                agg_policy = self.aggregation_func(state, policy).to(self.device)\n",
    "                action = torch.distributions.Categorical(agg_policy).sample()\n",
    "                action = self.choice_to_action(state, action)\n",
    "                state.update(action)\n",
    "            return self.vs_br(state, pi, player_idx)\n",
    "\n",
    "\n",
    "    def exploitability(self, runs=100):\n",
    "        total = 0\n",
    "        for run in range(runs):\n",
    "            if run % 100 == 0: print(f\"Run {run}\")\n",
    "\n",
    "            state = State(n_players=2)\n",
    "            self.begin_round(state)\n",
    "\n",
    "            # milli-bb (bb = 100 => mbb = money * 1000/100)\n",
    "            self.wprollout.fix(self.bot_hands[1], 1)\n",
    "            pi = torch.ones(26 * 51).to(self.device) / (26 * 51)\n",
    "            total += self.vs_br(copy.deepcopy(state), pi, 0) * 10 \n",
    "\n",
    "            self.wprollout.fix(self.bot_hands[0], 0)\n",
    "            pi = torch.ones(26 * 51).to(self.device) / (26 * 51)\n",
    "            total += self.vs_br(copy.deepcopy(state), pi, 1) * 10\n",
    "\n",
    "        return total / runs\n",
    "\n",
    "    def load_value_net(self):\n",
    "        ckpt = torch.load('/kaggle/input/pokerv4mini-ckpt/pytorch/default/1/value_net.pth', weights_only=True)\n",
    "        self.value_net.load_state_dict(ckpt[\"state\"])\n",
    "        self.optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
    "        print(f\"Loaded checkpoint at [sim {ckpt['sim'] + 1}]\")\n",
    "        return ckpt[\"sim\"] + 1\n",
    "\n",
    "    def load_policy_net(self):\n",
    "        ckpt = torch.load('/kaggle/input/pokerv4mini-ckpt/pytorch/default/1/policy_net.pth', weights_only=True)\n",
    "        self.policy_net.load_state_dict(ckpt[\"state\"])\n",
    "        self.policy_optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
    "        print(\"Loaded checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train_cfr.py\n",
    "\n",
    "class MCGame:\n",
    "    def __init__(self, load_ckpt=False, load_dataset=False):\n",
    "        self.losses = []\n",
    "        self.exploit = []\n",
    "        self.load_ckpt = load_ckpt\n",
    "        self.load_dataset = load_dataset\n",
    "        \n",
    "    def train(self, \n",
    "        n_iters: int, \n",
    "        K: int = 3000,\n",
    "        optim_steps: int = 4000,\n",
    "        batch_size: int = 10000\n",
    "    ):\n",
    "        sim_iter = 0\n",
    "        mccfr = MCCFR(n_players=2)\n",
    "        \n",
    "        M_Vp = ValueDataset()\n",
    "\n",
    "        if self.load_dataset:\n",
    "            # Change to path to value dataset\n",
    "            M_Vp.load(\"/kaggle/input/cfr-memory/value_dataset.pt\")\n",
    "            print(\"Loaded value dataset from /kaggle/input/cfr-memory/value_dataset.pt\")\n",
    "            print(torch.unique(M_Vp.T))\n",
    "\n",
    "        if self.load_ckpt:\n",
    "            sim_iter = mccfr.load_value_net()\n",
    "\n",
    "            # In Kaggle runs, kernel typically dies during optimization\n",
    "            # Change this as needed\n",
    "            print(\"Optimizing...\")\n",
    "            losses = mccfr.optimize(M_Vp, sim_iter, optim_steps, batch_size)\n",
    "            print(f\"[Sim {sim_iter}] mean loss:\", np.mean(losses))\n",
    "            self.losses.append(np.mean(losses))\n",
    "            sim_iter += 1\n",
    "               \n",
    "            \n",
    "        print(\"Starting game simulations\")\n",
    "        for _ in range(n_iters):\n",
    "            if sim_iter != 0 and sim_iter % 10 == 0: # exploitability check\n",
    "                expl = mccfr.exploitability(runs=500)\n",
    "                print(\"Exploitability:\", expl)\n",
    "                self.exploit.append(expl)\n",
    "\n",
    "            decisions = 0\n",
    "            for k in range(K):   \n",
    "                state = State(n_players=2)\n",
    "                mccfr.begin_round(state)\n",
    "                _ = mccfr.traverse(state, 0, M_Vp, sim_iter + 1)\n",
    "                decisions += mccfr.decisions\n",
    "            print(f\"[Sim {sim_iter}] average decision points:\", decisions / K)\n",
    "            \n",
    "            M_Vp.save()\n",
    "            print(f\"[Sim {sim_iter}] value dataset saved\")\n",
    "            \n",
    "            mccfr.optimizer.zero_grad() # flush gradients\n",
    "            torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "            print(f\"[Sim {sim_iter}] Optimizing...\")\n",
    "            losses = mccfr.optimize(M_Vp, sim_iter + 1, optim_steps, batch_size)\n",
    "\n",
    "            print(f\"[Sim {sim_iter}] mean loss:\", np.mean(losses))\n",
    "            self.losses.append(np.mean(losses))\n",
    "\n",
    "            mccfr.save_checkpoint(sim_iter)\n",
    "            print(f\"[Sim {sim_iter}] value net saved\")\n",
    "\n",
    "            sim_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "game = MCGame(load_ckpt=True, load_dataset=True)\n",
    "game.train(100) # Train for 1000 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_figs():\n",
    "    fig, axs = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "    axs[0].plot(range(len(game.losses)), game.losses)\n",
    "    axs[0].set_xlabel(\"simulation iter\")\n",
    "    axs[0].set_ylabel(\"avg decision point loss\")\n",
    "    \n",
    "    axs[1].plot(np.array(range(len(game.exploit))) * 1000, game.exploit)\n",
    "    axs[1].set_xlabel(\"simulation iter\")\n",
    "    axs[1].set_ylabel(\"exploitabilitiy (mbb/g)\")\n",
    "    \n",
    "    \n",
    "    fig.savefig('loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6174710,
     "sourceId": 10026627,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6385960,
     "sourceId": 10315132,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 202967,
     "modelInstanceId": 180717,
     "sourceId": 211998,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
